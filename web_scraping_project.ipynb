{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d0ab9ce-f685-417f-99b5-3e0d0c8c7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57c2ce0f-abfa-4dad-9425-4f21baca83fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"dropdown-item dropdown-state\" href=\"/state/al/index.htm\">\n",
      "Alabama\n",
      "</a>, <a class=\"dropdown-item dropdown-state\" href=\"/state/ak/index.htm\">\n",
      "Alaska\n",
      "</a>, <a class=\"dropdown-item dropdown-state\" href=\"/state/as/index.htm\">\n",
      "American Samoa\n",
      "</a>, <a class=\"dropdown-item dropdown-state\" href=\"/state/az/index.htm\">\n",
      "Arizona\n",
      "</a>, <a class=\"dropdown-item dropdown-state\" href=\"/state/ar/index.htm\">\n",
      "Arkansas\n",
      "</a>]\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://www.nps.gov/index.htm\")\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "parks_list = soup.find_all('a', class_='dropdown-state')\n",
    "\n",
    "# print only the first 5 things in the list\n",
    "print(parks_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47b936c6-da82-4467-bd8b-a07a1c4f3c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nps.gov/state/al/index.htm\n",
      "https://www.nps.gov/state/ak/index.htm\n",
      "https://www.nps.gov/state/as/index.htm\n",
      "https://www.nps.gov/state/az/index.htm\n",
      "https://www.nps.gov/state/ar/index.htm\n",
      "https://www.nps.gov/state/ca/index.htm\n",
      "https://www.nps.gov/state/co/index.htm\n",
      "https://www.nps.gov/state/ct/index.htm\n",
      "https://www.nps.gov/state/de/index.htm\n",
      "https://www.nps.gov/state/dc/index.htm\n"
     ]
    }
   ],
   "source": [
    "# this is a test\n",
    "for x in parks_list[:10]:\n",
    "    url = 'https://www.nps.gov' + x.attrs['href']\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ae9bc76-cd31-4008-90ef-3b65cab2066b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alcatraz Island', '/alca/', '', 'San Francisco, CA ', 'California']\n",
      "['Butterfield Overland', '/buov/', 'National Historic Trail', 'MO, AR, OK, TX, NM, AZ, CA ', 'California']\n",
      "['Cabrillo', '/cabr/', 'National Monument', 'San Diego, CA ', 'California']\n",
      "['California', '/cali/', 'National Historic Trail', 'Various States CA,CO,ID,KS,MO,NE,NV,OR,UT,WY ', 'California']\n",
      "['Castle Mountains', '/camo/', 'National Monument', 'Barstow, CA ', 'California']\n",
      "['César E. Chávez', '/cech/', 'National Monument', 'CA ', 'California']\n",
      "['Channel Islands', '/chis/', 'National Park', 'Ventura, CA ', 'California']\n",
      "['Death Valley', '/deva/', 'National Park', 'Death Valley, CA,NV ', 'California']\n",
      "['Devils Postpile', '/depo/', 'National Monument', 'the Sierra Nevada near     Mammoth Lakes, CA ', 'California']\n",
      "[\"Eugene O'Neill\", '/euon/', 'National Historic Site', 'Danville, CA ', 'California']\n",
      "['Fort Point', '/fopo/', 'National Historic Site', 'Presidio of San Francisco, CA ', 'California']\n",
      "['Golden Gate', '/goga/', 'National Recreation Area', 'San Francisco, CA ', 'California']\n",
      "['John Muir', '/jomu/', 'National Historic Site', 'Martinez, CA ', 'California']\n",
      "['Joshua Tree', '/jotr/', 'National Park', 'Southern California between I-10 and Hwy 62; headquarters in Twentynine Palms, CA ', 'California']\n",
      "['Juan Bautista de Anza', '/juba/', 'National Historic Trail', 'Nogales, AZ to San Francisco, CA, AZ,CA ', 'California']\n",
      "['Lassen Volcanic', '/lavo/', 'National Park', 'Mineral, CA ', 'California']\n",
      "['Lava Beds', '/labe/', 'National Monument', 'Tulelake, CA ', 'California']\n",
      "['Manzanar', '/manz/', 'National Historic Site', 'Independence, CA ', 'California']\n",
      "['Mojave', '/moja/', 'National Preserve', 'Southern California between I-15 and I-40; headquarters in Barstow, CA ', 'California']\n",
      "['Muir Woods', '/muwo/', 'National Monument', 'Mill Valley, CA ', 'California']\n",
      "['Old Spanish', '/olsp/', 'National Historic Trail', 'AZ,CA,CO,NV,NM,UT ', 'California']\n",
      "['Pinnacles', '/pinn/', 'National Park', 'Paicines, CA ', 'California']\n",
      "['Point Reyes', '/pore/', 'National Seashore', 'Point Reyes, CA ', 'California']\n",
      "['Pony Express', '/poex/', 'National Historic Trail', 'Various States CA,CO,KS,MO,NE,NV,UT,WY ', 'California']\n",
      "['Port Chicago Naval Magazine', '/poch/', 'National Memorial', 'Concord Naval Weapons Station, CA ', 'California']\n",
      "['Presidio of San Francisco', '/prsf/', '', 'San Francisco, CA ', 'California']\n",
      "['Redwood', '/redw/', 'National and State Parks', 'Del Norte & Humboldt counties , CA ', 'California']\n",
      "['Rosie the Riveter WWII Home Front', '/rori/', 'National Historical Park', 'Richmond, CA ', 'California']\n",
      "['San Francisco Maritime', '/safr/', 'National Historical Park', 'San Francisco, CA ', 'California']\n",
      "['Santa Monica Mountains', '/samo/', 'National Recreation Area', 'Thousand Oaks, CA ', 'California']\n",
      "['Sequoia & Kings Canyon', '/seki/', 'National Parks', 'In the southern Sierra Nevada in Tulare and Fresno counties, CA ', 'California']\n",
      "['Tule Lake', '/tule/', 'National Monument', 'Tulelake, CA ', 'California']\n",
      "['Whiskeytown', '/whis/', 'National Recreation Area', 'Whiskeytown, CA ', 'California']\n",
      "['Yosemite', '/yose/', 'National Park', 'the Sierra Nevada, CA ', 'California']\n"
     ]
    }
   ],
   "source": [
    "# open one state page and try to scrape it here as a test\n",
    "# https://www.nps.gov/state/ca/index.htm\n",
    "\n",
    "url = 'https://www.nps.gov/state/ca/index.htm'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# Get the page title - the state name\n",
    "park_state = soup.find('h1', class_='page-title').get_text()\n",
    "\n",
    "# The 'ul' holds all the parks \n",
    "parks = soup.find('ul', id='list_parks')\n",
    "\n",
    "# Each 'li' holds one park\n",
    "details_list = parks.find_all('li')\n",
    "\n",
    "# Loop to get stuff from each 'li' in the list - one park per 'li'\n",
    "for x in details_list:\n",
    "    try:\n",
    "        park_name = x.find('h3').find('a').get_text()\n",
    "        a_tag = x.find('h3').find(\"a\")\n",
    "        park_name = a_tag.text\n",
    "        park_url = a_tag.attrs['href']\n",
    "        park_type = x.find('p', class_='list_left__kicker').get_text()\n",
    "        park_city = x.find('p', class_='list_left__subtitle').get_text()\n",
    "        print( [park_name, park_url, park_type, park_city, park_state] )\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f85aef87-1db5-442c-83e0-f6e2fe70607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csvfile = open('parks.csv', 'w', newline='', encoding='utf-8')\n",
    "\n",
    "c = csv.writer(csvfile)\n",
    "\n",
    "c.writerow( ['park_name', 'park_url', 'park_type', 'park_city', 'park_state'] )\n",
    "\n",
    "for x in parks_list:\n",
    "    url = 'https://www.nps.gov' + x.attrs['href']\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Get the page title - the state name\n",
    "    park_state = soup.find('h1', class_='page-title').get_text()\n",
    "\n",
    "    # The 'ul' holds all the parks \n",
    "    parks = soup.find('ul', id='list_parks')\n",
    "\n",
    "    # Each 'li' holds one park\n",
    "    details_list = parks.find_all('li')\n",
    "\n",
    "    # Loop to get stuff from each 'li' in the list - one park per 'li'\n",
    "    for x in details_list:\n",
    "        try:\n",
    "            park_name = x.find('h3').find('a').get_text()\n",
    "            a_tag = x.find('h3').find(\"a\")\n",
    "            park_name = a_tag.text\n",
    "            park_url = a_tag.attrs['href']\n",
    "            park_type = x.find('p', class_='list_left__kicker').get_text()\n",
    "            park_city = x.find('p', class_='list_left__subtitle').get_text()\n",
    "            c.writerow( [park_name, park_url, park_type, park_city, park_state] )\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "csvfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ad5c9-367c-48bf-b9d2-f1e3cbda6f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
